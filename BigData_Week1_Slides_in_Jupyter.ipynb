{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e994cd",
   "metadata": {},
   "source": [
    "# รายวิชา: ข้อมูลขนาดใหญ่ (Big Data)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/witsarutsarai12-Academic/128-356-Big-Data/blob/main/BigData_Week1_Slides_in_Jupyter.ipynb)\n",
    "\n",
    " สัปดาห์ที่ 1: บทนำ + Python พื้นฐานสำหรับ Data Science \n",
    "\n",
    "\n",
    "Notebook นี้ออกแบบให้ใช้สอนแบบ **สไลด์ใน Jupyter** (ข้อความอ่านได้ + โค้ดทดลอง) โดยแบ่งเป็นช่วงย่อย\n",
    "- Part 0 เตรียมสภาพแวดล้อม \n",
    "- Part 1 แนะนำผู้สอน \n",
    "- Part 2 แนะนำรายวิชาและภาพรวมการประเมิน \n",
    "- Part 3 Big Data คืออะไร \n",
    "- Part 3.1 พัฒนาการทางประวัติศาสตร์ของ Big Data \n",
    "- Part 4 ทำไม Python คือภาษาหลักของงานข้อมูล \n",
    "- Part 5 Python พื้นฐาน (Hands-on) \n",
    "- Part 6 Python สำหรับ Data Science \n",
    "- Part 7 เชื่อมไปสัปดาห์ถัดไป\n",
    "- Part 8 สรุปท้ายคาบ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc676269",
   "metadata": {},
   "source": [
    "## Part 0: การเตรียมสภาพแวดล้อม\n",
    "\n",
    "การเตรียมสภาพแวดล้อม (Environment Setup) เป็นก้าวแรกที่สำคัญของนักข้อมูล การตรวจสอบเวอร์ชันของเครื่องมือช่วยลดปัญหาความเข้ากันได้ (Compatibility Issues) ที่อาจเกิดขึ้นเมื่อทำงานร่วมกับทีม หรือเมื่อนำโค้ดไปรันในเครื่องอื่น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตรวจสอบเวอร์ชัน Python\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d63673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตรวจสอบไลบรารีหลัก\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(np.__version__, pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5686f14",
   "metadata": {},
   "source": [
    "## Part 1: แนะนำผู้สอน\n",
    "\n",
    "### ผู้สอนรายวิชา\n",
    "- ชื่อ–สกุล: วิศรุต สาหร่าย\n",
    "- บทบาทและประสบการณ์:\n",
    "  - Data Engineer / Data Scientist - US Startup\n",
    "  - งานระบบข้อมูลขนาดใหญ่ (Data Pipeline / Cloud / Spark)\n",
    "  - งานวิเคราะห์ข้อมูลเชิงธุรกิจและการนำเสนอผลลัพธ์\n",
    "\n",
    "**เป้าหมายการเรียนรู้ร่วมกัน**\n",
    "- สร้างความเข้าใจเชิงโครงสร้าง ไม่ใช่แค่การใช้เครื่องมือ\n",
    "- ฝึกทำงานข้อมูลแบบทำซ้ำได้ (reproducible) และอธิบายได้ (explainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a4da9",
   "metadata": {},
   "source": [
    "## Part 2: แนะนำรายวิชาและ Syllabus\n",
    "\n",
    "### รายวิชานี้เรียนอะไรบ้าง\n",
    "ในรายวิชานี้ เราจะเน้นสร้างความเข้าใจพื้นฐานที่แข็งแรง เพื่อให้นักศึกษาสามารถต่อยอดไปยังเครื่องมือระดับสูงได้\n",
    "- Big Data คืออะไร (ในโลกจริง) และทำไมเราถึงต้องสนใจ\n",
    "- Data Pipeline: ingest → clean → transform → analyze (หัวใจของการทำงานข้อมูล)\n",
    "- เครื่องมือที่ใช้จริงในอุตสาหกรรม และแนวโน้มเทคโนโลยีล่าสุด\n",
    "\n",
    "### รูปแบบการเรียน\n",
    "- Lecture + Hands-on ใน Jupyter Notebook\n",
    "- เน้นการคิดเชิงระบบและการทำงานกับข้อมูลขนาดใหญ่กว่าเครื่องมือทั่วไป\n",
    "\n",
    "### การประเมิน (ตัวอย่างโครงสร้าง)\n",
    "- Final Project (เลือกความยากได้): ทำ pipeline กับข้อมูลขนาดใหญ่และทำ dashboard\n",
    "- สอบกลางภาค / ปลายภาค: เน้นความเข้าใจแนวคิดและการอธิบายเหตุผล\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9718f2",
   "metadata": {},
   "source": [
    "## Part 3: Big Data คืออะไร\n",
    "\n",
    "> **วัตถุประสงค์ของช่วงนี้**: ให้นักศึกษาสามารถนิยาม Big Data ได้อย่างถูกต้องในเชิงระบบ แยกแยะจากคำศัพท์ที่เกี่ยวข้อง และเข้าใจ “เหตุผล” ที่ทำให้ต้องมีเครื่องมือ Big Data รวมถึงเห็นภาพว่าข้อมูลในโลกความเป็นจริงนั้นมีความซับซ้อนเพียงใด\n",
    "\n",
    "\n",
    "**มุมมองจากผู้เชี่ยวชาญ (Definitions)**\n",
    "- **Gartner (2001)**: เน้นที่ 3Vs (Volume, Velocity, Variety) เป็นนิยามคลาสสิก\n",
    "- **Oracle**: เน้นที่ \"Value\" - ข้อมูลจะมีค่าก็ต่อเมื่อนำมาใช้ประโยชน์ได้\n",
    "- **Wikipedia**: เน้นที่ \"ความซับซ้อน\" จนซอฟต์แวร์ประมวลผลข้อมูลแบบเดิม (Standard Data Processing Software) รับมือไม่ได้\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2baa3",
   "metadata": {},
   "source": [
    "### ปัญหาข้อมูลในโลกจริง (Reality of Data)\n",
    "\n",
    "ในโลกจริง ข้อมูลไม่ได้ถูกสร้างเพื่อการวิเคราะห์ แต่เกิดจากกิจกรรมและระบบงาน เช่น การซื้อขาย การใช้งานแอป การสื่อสาร และอุปกรณ์ IoT\n",
    "\n",
    "**ลักษณะของข้อมูลจริง**\n",
    "- เกิดขึ้นตลอดเวลา และเพิ่มขึ้นอย่างต่อเนื่อง (Continuous Growth)\n",
    "- มีหลายรูปแบบ (Structured, Semi-structured, Unstructured) เช่น ตัวเลข ข้อความ ภาพ เสียง พิกัด\n",
    "- มีความผิดพลาด ขาดหาย ซ้ำซ้อน และมี noise (Dirty Data) ซึ่งต้องอาศัยการทำความสะอาดก่อนนำไปใช้\n",
    "\n",
    "**ช่วงถาม–คิด**\n",
    "- ข้อมูล “จริง” แตกต่างจากข้อมูลในแบบฝึกหัดอย่างไร\n",
    "\n",
    "\n",
    "![messy_vs_clean_data](images/messy_vs_clean_data_1768465020694.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479f973",
   "metadata": {},
   "source": [
    "### นิยาม Big Data (Definition as a System Constraint)\n",
    "\n",
    "Big Data คือชุดข้อมูลหรือภาระงาน (workload) ที่มี **ขนาด ความเร็ว ความหลากหลาย หรือความไม่แน่นอน** สูงจนทำให้การจัดการด้วยเครื่องมือดั้งเดิมไม่เพียงพอ\n",
    "\n",
    "**ประเด็นสำคัญ**\n",
    "- Big Data ไม่ได้หมายถึง “ไฟล์ใหญ่” อย่างเดียว\n",
    "- Big Data คือ **ข้อจำกัดของระบบเดิม** เมื่อเจอข้อมูลจริง\n",
    "\n",
    "> กล่าวอีกนัยหนึ่ง: Big Data คือ “ปัญหา” มากกว่า “เทคโนโลยี”\n",
    "\n",
    "\n",
    "\n",
    "**นิยามจากองค์กรชั้นนำ (Definitions)**\n",
    "- **Gartner (2001)**: \"Big Data is high-volume, high-velocity and/or high-variety information assets that demand cost-effective, innovative forms of information processing.\" (ต้นกำเนิด 3Vs)\n",
    "- **Oracle**: \"Big Data is the derivation of value from traditional relational database driven business decision making, augmented with new sources of unstructured data.\" (เน้นที่ Value)\n",
    "- **NIST**: \"Big Data consists of extensive datasets primarily in the characteristics of volume, variety, speed, and/or variability that require a scalable architecture for efficient storage, manipulation, and analysis.\" (เน้น Architecture)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83d5e2",
   "metadata": {},
   "source": [
    "### ข้อจำกัดของเครื่องมือดั้งเดิม (Why Excel / Single DB Fail)\n",
    "\n",
    "เครื่องมือดั้งเดิมมักทำงานบนเครื่องเดียว (single machine) จึงติดข้อจำกัดเชิงฟิสิกส์\n",
    "\n",
    "**ข้อจำกัดที่พบได้จริง**\n",
    "เมื่อปริมาณข้อมูลเกินขีดจำกัดของ Hardware เครื่องเดียว เราจะเจอปัญหา:\n",
    "- หน่วยความจำ (RAM) ไม่พอ → เปิดไฟล์ไม่ได้ Program Crash หรือทำงานช้ามาก\n",
    "- CPU ไม่พอ → การคำนวณที่ซับซ้อนใช้เวลานานเกินไป (เช่น เป็นวันหรือสัปดาห์)\n",
    "- I/O (อ่าน/เขียน) เป็นคอขวด → การอ่านไฟล์ขนาดใหญ่กินเวลานาน\n",
    "- การทำงานพร้อมกันหลายคน (Concurrency) ทำได้ยากและเสี่ยงต่อข้อมูลเสียหาย\n",
    "\n",
    "**ตัวอย่างสถานการณ์**\n",
    "- ไฟล์ CSV ขนาด 5–20GB: เปิดไม่ได้ในเครื่องทั่วไป\n",
    "- การ Join ข้อมูลหลายตารางขนาดใหญ่: ใช้เวลานานมาก\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3559e",
   "metadata": {},
   "source": [
    "### 5Vs ของ Big Data (มองให้เป็น “ปัญหา”)\n",
    "\n",
    "การใช้ 5Vs ไม่ใช่เพื่อท่องจำ แต่เพื่อ “จำแนกชนิดของปัญหา”\n",
    "\n",
    "- **Volume**: ปริมาณข้อมูลมหาศาล จนเกินขีดจำกัดการเก็บและประมวลผลของเครื่องเดียว\n",
    "- **Velocity**: ความเร็วของข้อมูลที่เข้ามาอย่างต่อเนื่อง เช่น ข้อมูลจาก Sensor หรือ Social Media ที่ต้องการการประมวลผลแบบ Real-time\n",
    "- **Variety**: ความหลากหลายของรูปแบบข้อมูล ทั้ง Structured (SQL), Semi-structured (JSON, XML), และ Unstructured (Image, Video, Text)\n",
    "- **Veracity**: ความถูกต้องและความน่าเชื่อถือของข้อมูล ซึ่งข้อมูล Big Data มักมีความไม่แน่นอนสูง\n",
    "- **Value**: คุณค่าที่ซ่อนอยู่ ข้อมูลจะมีประโยชน์ก็ต่อเมื่อเราสามารถสกัด Insight ออกมาตัดสินใจได้จริง\n",
    "\n",
    "**ช่วงถาม–คิด**\n",
    "- ปัญหาที่ทำให้ระบบล่มบ่อยที่สุดอยู่ใน V ใด และเพราะอะไร\n",
    "\n",
    "\n",
    "![big_data_5vs](images/big_data_5vs_1768464556575.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c847f8f",
   "metadata": {},
   "source": [
    "### Big Data vs Traditional Data (เปรียบเทียบเชิงสถาปัตยกรรม)\n",
    "\n",
    "| มิติ | Traditional Data | Big Data |\n",
    "|---|---|---|\n",
    "| ขนาด | MB–GB | TB–PB หรือมากกว่า |\n",
    "| การประมวลผล | Batch รายงานย้อนหลัง | Batch + Streaming + Interactive |\n",
    "| สถาปัตยกรรม | Single-node | Distributed / Cluster |\n",
    "| การขยาย | Vertical scaling | Horizontal scaling |\n",
    "| รูปแบบข้อมูล | ส่วนใหญ่ Structured | Structured + Semi + Unstructured |\n",
    "\n",
    "**สรุป**\n",
    "Big Data ไม่ได้เปลี่ยน “เป้าหมาย” ของการวิเคราะห์ แต่เปลี่ยน “วิธี” ที่ต้องทำเพื่อให้ระบบรองรับได้\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e8ac1",
   "metadata": {},
   "source": [
    "### ตัวอย่างเชิงกรณีศึกษา (E-commerce / Platform)\n",
    "\n",
    "สมมติแพลตฟอร์มมี:\n",
    "- ผู้ใช้งาน 500,000 คน/วัน\n",
    "- Event log เฉลี่ย 50 events/คน/วัน → 25,000,000 events/วัน\n",
    "- ข้อมูลคำสั่งซื้อ 200,000 รายการ/วัน\n",
    "- ข้อมูลข้อความรีวิวและรูปภาพสินค้า\n",
    "\n",
    "**คำถามที่องค์กรต้องตอบ**\n",
    "- รายได้วันนี้เทียบกับสัปดาห์ก่อนเป็นอย่างไร\n",
    "- สินค้าชนิดใดถูกคืนสูงผิดปกติ\n",
    "- แคมเปญโฆษณาทำให้ conversion ดีขึ้นจริงหรือไม่\n",
    "\n",
    "**ช่วงถาม–คิด**\n",
    "- หากต้องได้คำตอบภายใน 5 นาที ระบบควรออกแบบแบบใด\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58e4d9",
   "metadata": {},
   "source": [
    "### Big Data กับบทบาทในองค์กร (Why it matters)\n",
    "\n",
    "Big Data สำคัญเพราะช่วยให้เกิดการตัดสินใจที่:\n",
    "- เร็วขึ้น (timely)\n",
    "- แม่นยำขึ้น (better evidence)\n",
    "- รองรับสถานการณ์ซับซ้อน (complexity)\n",
    "\n",
    "**ตัวอย่างผลลัพธ์ที่จับต้องได้**\n",
    "- ลดต้นทุนการปฏิบัติการ (optimize logistics)\n",
    "- เพิ่มรายได้ (recommendation / targeting)\n",
    "- ลดความเสี่ยง (fraud detection)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cd498",
   "metadata": {},
   "source": [
    "### ทำไมต้องมี Data Pipeline (From Raw to Usable)\n",
    "\n",
    "ข้อมูลดิบ (Raw data) ไม่สามารถใช้วิเคราะห์ได้ทันที ต้องผ่านกระบวนการ\n",
    "\n",
    "**Pipeline ขั้นพื้นฐาน**\n",
    "1) **Ingest**: นำเข้าข้อมูลจากแหล่งต่างๆ (Database, API, Logs)\n",
    "2) **Clean**: ทำความสะอาดข้อมูล จัดการค่าที่หายไป (Null) หรือค่าที่ผิดปกติ (Outliers)\n",
    "3) **Transform**: แปลงรูปแบบข้อมูลให้พร้อมใช้ เช่น เปลี่ยนรูปแบบวันที่, รวมตาราง\n",
    "4) **Store**: จัดเก็บลงระบบที่เหมาะสม (Data Warehouse, Data Lake)\n",
    "5) **Analyze**: วิเคราะห์หา Insight หรือนำไปสร้าง Model\n",
    "\n",
    "**ตัวอย่างง่าย**\n",
    "- CSV → แปลงเป็น Parquet → อ่านเร็วขึ้น → วิเคราะห์ได้ไวขึ้น\n",
    "\n",
    "\n",
    "![data_pipeline_flow](images/data_pipeline_flow_1768464591379.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34c9b7",
   "metadata": {},
   "source": [
    "### สรุปนิยามที่ถูกต้อง (Key Takeaways)\n",
    "\n",
    "- Big Data คือ “ปัญหาเชิงระบบ” ที่เกิดจากข้อจำกัดของเครื่องมือดั้งเดิม\n",
    "- เทคโนโลยี Big Data เกิดขึ้นเพื่อแก้ปัญหา 5Vs\n",
    "- เป้าหมายของรายวิชาคือให้ทำ Pipeline ได้จริงและเข้าใจโครงสร้างระบบ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240275a5",
   "metadata": {},
   "source": [
    "## Part 3.1: พัฒนาการทางประวัติศาสตร์ของ Big Data\n",
    "\n",
    "> วัตถุประสงค์: เห็นวิวัฒนาการของ “การจัดการข้อมูล” ตั้งแต่ฐานข้อมูลในองค์กร → ERP/SAP → web-scale → NoSQL → Data Lake/Lakehouse\n",
    "\n",
    "![evolution_timeline](images/evolution_timeline_1768464611899.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e44d69",
   "metadata": {},
   "source": [
    "### File-based Systems (ยุคข้อมูลกระจัดกระจาย)\n",
    "\n",
    "- องค์กรจำนวนมากเริ่มจากการเก็บข้อมูลเป็นไฟล์ (CSV, Excel, Text)\n",
    "- ข้อดี: เริ่มง่าย ต้นทุนต่ำ\n",
    "- ข้อจำกัด: ซ้ำซ้อนสูง, เวอร์ชันไม่ตรงกัน, เชื่อมโยงข้อมูลยาก, ควบคุมคุณภาพยาก\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4479549c",
   "metadata": {},
   "source": [
    "### ฐานข้อมูล (Database) เกิดขึ้นเพื่ออะไร\n",
    "\n",
    "แนวคิดฐานข้อมูลเกิดขึ้นเพื่อแก้ปัญหาไฟล์กระจัดกระจาย โดยทำให้ข้อมูล\n",
    "- มีศูนย์กลาง (Centralized) ทำให้บริหารจัดการง่าย\n",
    "- มีมาตรฐานและตรวจสอบได้ (Data Integrity)\n",
    "- รองรับผู้ใช้หลายคนพร้อมกัน (Concurrency Control)\n",
    "\n",
    "องค์ประกอบสำคัญที่ทำให้ Database ต่างจากไฟล์:\n",
    "- การกำหนดโครงสร้างข้อมูล (schema)\n",
    "- ดัชนี (index) เพื่อค้นหาเร็ว\n",
    "- การควบคุมสิทธิ์และการทำงานพร้อมกัน (concurrency)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0eb95",
   "metadata": {},
   "source": [
    "### Relational Database (RDBMS) และ SQL\n",
    "\n",
    "- จัดข้อมูลเป็นตาราง + ความสัมพันธ์ระหว่างตาราง\n",
    "- ใช้ SQL ในการสืบค้นและสรุปข้อมูล\n",
    "- จุดแข็ง: ความถูกต้อง (ACID), ความสัมพันธ์ชัดเจน, ใช้ได้ดีมากกับงานธุรกรรม (OLTP)\n",
    "\n",
    "ข้อจำกัด:\n",
    "- เมื่อข้อมูลโตมาก/ผู้ใช้มาก การขยายระบบมีต้นทุนสูง และมักติดปัญหา scale แบบเครื่องเดียว\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f8271",
   "metadata": {},
   "source": [
    "### สิ่งที่ RDBMS ทำได้ดี และสิ่งที่เริ่มเป็นข้อจำกัด\n",
    "\n",
    "**RDBMS ทำได้ดี**\n",
    "- ข้อมูลธุรกรรม: การเงิน การสั่งซื้อ การลงทะเบียน\n",
    "- ความถูกต้องและการบันทึกประวัติ\n",
    "\n",
    "**ข้อจำกัดที่เริ่มชัดเมื่อข้อมูลโต**\n",
    "- งานวิเคราะห์ที่ต้อง scan จำนวนมากทำให้ช้า\n",
    "- ข้อมูลนอกตาราง (ข้อความ/ภาพ/log) เก็บและใช้งานยาก\n",
    "- ขยายระบบแบบแนวนอนทำได้ยากกว่าแบบไฟล์/ระบบกระจาย\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e715bbf",
   "metadata": {},
   "source": [
    "### ยุคข้อมูลธุรกิจ — ERP (Business Process Data)\n",
    "\n",
    "ก่อนคำว่า Big Data จะเป็นที่นิยม องค์กรธุรกิจมี “ข้อมูลจำนวนมาก” อยู่แล้วจากระบบงานหลัก\n",
    "\n",
    "- **ERP (Enterprise Resource Planning)** เก็บข้อมูลกระบวนการธุรกิจ เช่น บัญชี การเงิน จัดซื้อ คลังสินค้า การผลิต\n",
    "- เป้าหมายหลัก: ทำให้ข้อมูล “ถูกต้อง” และ “เป็นมาตรฐานเดียว” เพื่อการควบคุมภายในและการตัดสินใจ\n",
    "\n",
    "ข้อจำกัด:\n",
    "- ออกแบบเพื่อ “งานปฏิบัติการ” (OLTP) มากกว่างานวิเคราะห์เชิงลึก\n",
    "- รายงานหนัก ๆ ทำให้ระบบช้าหรือกระทบงานธุรกรรม\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d43b82",
   "metadata": {},
   "source": [
    "### ERP → SAP และการทำมาตรฐานข้อมูลองค์กร\n",
    "\n",
    "- การเติบโตของแพลตฟอร์ม ERP ระดับองค์กร เช่น **SAP** ทำให้ข้อมูลธุรกิจถูกทำให้เป็นมาตรฐาน\n",
    "- องค์กรเริ่มมีข้อมูลที่เชื่อมโยงข้ามหน่วยงานได้มากขึ้น (end-to-end process)\n",
    "\n",
    "ข้อจำกัดที่เริ่มชัด:\n",
    "- ต้องการรายงานและการวิเคราะห์ที่หลากหลายมากขึ้น\n",
    "- งานวิเคราะห์บน OLTP ทำให้เกิดปัญหาคอขวดด้านประสิทธิภาพ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead38516",
   "metadata": {},
   "source": [
    "### OLTP vs OLAP (แยกชนิดงาน)\n",
    "\n",
    "- **OLTP (Online Transaction Processing)**: งานธุรกรรม เน้นเร็วและถูกต้อง (insert/update สูง) เช่น ระบบธนาคาร\n",
    "- **OLAP (Online Analytical Processing)**: งานวิเคราะห์ เน้นการสรุป/รวม/เจาะลึก (scan/aggregate สูง) เช่น ออกรายงานประจำปี\n",
    "\n",
    "บทเรียนสำคัญ:\n",
    "- ระบบเดียวทำทั้ง OLTP และ OLAP พร้อมกันมักทำให้ประสิทธิภาพตกและบริหารยาก\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe181fa4",
   "metadata": {},
   "source": [
    "### Data Warehouse และ ETL (1995–2005)\n",
    "\n",
    "- แนวคิดสำคัญ: แยกพื้นที่วิเคราะห์ออกจากระบบธุรกรรม\n",
    "- ใช้ **ETL** ดึงข้อมูลจากหลายระบบ → ทำความสะอาด/มาตรฐาน → โหลดเข้า Warehouse\n",
    "- รองรับ BI และรายงานย้อนหลัง\n",
    "\n",
    "ข้อจำกัด:\n",
    "- ยืดหยุ่นต่ำ เปลี่ยน schema ยาก\n",
    "- ไม่เหมาะกับข้อมูลนอกตาราง (ข้อความ/ภาพ/ล็อก)\n",
    "- ความหน่วงในการได้ข้อมูล (latency) สูง\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4777d40",
   "metadata": {},
   "source": [
    "### การระเบิดของข้อมูลยุคเว็บ (Web-scale)\n",
    "\n",
    "- Web/App ทำให้เกิดข้อมูลชนิดใหม่จำนวนมหาศาล เช่น clickstream, search log, ad impression\n",
    "- ข้อมูลเกิดเร็วและมากกว่าที่ warehouse แบบเดิมรองรับได้\n",
    "\n",
    "ผลที่ตามมา:\n",
    "- ต้องการระบบที่เก็บได้ “มหาศาล” และประมวลผลได้ “แบบกระจาย”\n",
    "\n",
    "\n",
    "\n",
    "**เกร็ดประวัติศาสตร์: Information Explosion (2000s)**\n",
    "การเกิดขึ้นของ Search Engine (Google, Yahoo) และ Social Media (Facebook, Twitter) ทำให้โลกเปลี่ยนจากยุค \"มนุษย์ป้อนข้อมูล\" (Data Entry) เป็นยุค \"มนุษย์ทิ้งร่องรอยดิจิทัล\" (Digital Footprint)\n",
    "- **Crawl & Index**: การเก็บข้อมูลเว็บทั่วโลกต้องใช้วิธีคิดใหม่ที่ไม่ใช่แค่ database\n",
    "- **User Generated Content**: ข้อมูลไม่ได้มาจากองค์กรฝ่ายเดียวอีกต่อไป\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616f5ee",
   "metadata": {},
   "source": [
    "### แนวคิด Distributed Systems (พื้นฐานสำคัญ)\n",
    "\n",
    "- แบ่งข้อมูลและงานออกเป็นหลายเครื่อง (horizontal scaling)\n",
    "- ได้ throughput สูงขึ้น\n",
    "- ต้องออกแบบให้รองรับความล้มเหลวของเครื่อง (fault tolerance)\n",
    "\n",
    "\n",
    "\n",
    "**เกร็ดความรู้: Site Reliability Engineering (SRE)**\n",
    "ในระบบขนาดใหญ่ที่มีเครื่องเซิร์ฟเวอร์พันเครื่อง \"ความล้มเหลวคือเรื่องปกติ\" (Failure is normal).\n",
    "แนวคิดของ Google SRE คือ:\n",
    "- **\"Hope is not a strategy\"**: อย่าหวังว่า hardware จะไม่พัง\n",
    "- ออกแบบ Software ให้ **resilient**: ถ้าเครื่องพัง 10% ระบบต้องทำงานต่อได้โดย user ไม่รู้ตัว (Redundancy & Failover)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f2bed",
   "metadata": {},
   "source": [
    "### Google File System (GFS) — การเก็บข้อมูลแบบกระจาย\n",
    "\n",
    "- แนวคิด file system แบบกระจายเพื่อเก็บข้อมูลปริมาณมากบนเครื่องราคาทั่วไป\n",
    "- ออกแบบให้ “ล้มได้” แต่ระบบยังทำงานต่อได้\n",
    "\n",
    "\n",
    "\n",
    "**เกร็ดความรู้: หลักการทำงานเบื้องหลัง**\n",
    "- **Chunk Servers**: เครื่องคอมพิวเตอร์ธรรมดา (commodity hardware) จำนวนมากที่เก็บชิ้นส่วนไฟล์\n",
    "- **Master Node**: เครื่องหลักที่คอยจดจำว่า \"ชิ้นส่วนไหน\" เก็บอยู่ที่ \"เครื่องใด\"\n",
    "หากเครื่องใดพัง ระบบจะสำเนาข้อมูลจากเครื่องอื่นมาทดแทนทันที ทำให้ข้อมูลไม่หาย\n",
    "\n",
    "\n",
    "\n",
    "**เกร็ดความรู้: เบื้องหลังความเสถียร (SRE Mindset)**\n",
    "Google มองว่า \"Hardware พังเป็นเรื่องปกติ\" (Failure is normal)\n",
    "- แทนที่จะซื้อ Server ราคาแพงที่ไม่พังง่าย (Supercomputer)\n",
    "- Google ใช้ Commodity Hardware (ราคาถูก) จำนวนมาก แล้วจัดการความเสถียรด้วย Software\n",
    "- **Colossus**: คือระบบไฟล์รุ่นลูกของ GFS ที่พัฒนาขึ้นมาเพื่อแก้ข้อจำกัดเรื่อง Real-time และรองรับไฟล์จำนวนมหาศาลได้ดียิ่งขึ้น (เช่น ใช้ใน YouTube, Drive)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5296d",
   "metadata": {},
   "source": [
    "### MapReduce — การประมวลผลแบบแบ่งงาน\n",
    "\n",
    "- Map: กระจายงานย่อยไปหลายเครื่อง\n",
    "- Reduce: รวมผลลัพธ์กลับมาเป็นคำตอบ\n",
    "\n",
    "ข้อดี:\n",
    "- ประมวลผลข้อมูลใหญ่ได้ด้วย cluster\n",
    "\n",
    "ข้อจำกัด:\n",
    "- งานหลายขั้นตอนซับซ้อน\n",
    "- ช้าเพราะต้องอ่าน/เขียนลง disk บ่อย\n",
    "\n",
    "\n",
    "![mapreduce_concept](images/mapreduce_concept_1768464638482.png)\n",
    "\n",
    "\n",
    "\n",
    "**ขั้นตอนการทำงาน (Walk-through)**\n",
    "1. **Input**: ข้อมูลขนาดใหญ่ถูกแบ่งเป็นส่วนย่อย\n",
    "2. **Map**: กระจายงานไปให้ Worker หลายเครื่องประมวลผลขนานกัน (เช่น นับคำในแต่ละส่วน)\n",
    "3. **Shuffle**: จัดกลุ่มผลลัพธ์ที่เหมือนกันมารวมกัน (เช่น รวมคำว่า \"Apple\" จากทุกเครื่อง)\n",
    "4. **Reduce**: ผสานผลลัพธ์สุดท้าย (เช่น รวมจำนวน \"Apple\" ทั้งหมดได้ 500 คำ)\n",
    "5. **Output**: เขียนผลลัพธ์ลง Disk\n",
    "\n",
    "\n",
    "\n",
    "**รู้จักกับ Bigtable: ปู่ของ NoSQL**\n",
    "- Google สร้าง **Bigtable** (2006) เพื่อเก็บข้อมูลที่มีโครงสร้างยืดหยุ่น เช่น ข้อมูลหน้าเว็บมหาศาลสำหรับ Google Search\n",
    "- มันเป็นต้นแบบของฐานข้อมูล NoSQL แบบ Wide-column store (เช่น Apache HBase, Cassandra)\n",
    "- จุดเด่นคือการอ่าน/เขียนได้เร็วมาก และขยายตัวได้ง่าย\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d65dc",
   "metadata": {},
   "source": [
    "### Bigtable — แนวคิดฐานข้อมูลแบบกระจายระดับเว็บ\n",
    "\n",
    "- รองรับข้อมูลขนาดใหญ่แบบ web-scale\n",
    "- เน้นการ scale ในแนวนอนและ throughput\n",
    "- สะท้อนแนวคิดว่า “ฐานข้อมูลสำหรับยุคเว็บ” ต้องต่างจาก RDBMS แบบเดิม\n",
    "\n",
    "\n",
    "\n",
    "**Bigtable vs RDBMS**\n",
    "- Bigtable ไม่รองรับ SQL เต็มรูปแบบ (ในยุคแรก) และไม่มี Join ที่ซับซ้อน\n",
    "- ออกแบบมาให้ \"Denormalize\" ข้อมูล (เก็บซ้ำได้) เพื่อให้อ่านประมวลผลได้เร็วที่สุด\n",
    "\n",
    "\n",
    "\n",
    "**Bigtable (The Base of Modern NoSQL)**\n",
    "เป็นต้นแบบของ HBase และ Cassandra\n",
    "- **Wide-column store**: เก็บข้อมูลเหมือนตารางยักษ์ที่มีเป็นล้าน column ได้\n",
    "- **Sparse data**: ช่องไหนไม่มีค่า ก็ไม่กินที่เก็บจริง (ต่างจาก RDBMS ที่ NULL ก็อาจกินที่)\n",
    "เหมาะสำหรับเก็บ Web Index หรือ User History ขนาดใหญ่\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3553d87",
   "metadata": {},
   "source": [
    "### Colossus — พัฒนาการของระบบจัดเก็บเมื่อข้อมูลโตขึ้น\n",
    "\n",
    "- เมื่อปริมาณและชนิดงานโตขึ้น ระบบจัดเก็บต้องพัฒนาให้จัดการ metadata และการใช้งานหลากหลายได้ดีขึ้น\n",
    "- สะท้อนบทเรียนว่า เมื่อข้อมูลโตเป็นหลายลำดับขนาด (order of magnitude) สถาปัตยกรรม storage ต้องเปลี่ยนตาม\n",
    "\n",
    "\n",
    "\n",
    "**ทำไมต้อง Colossus?**\n",
    "- GFS ยุคแรกมีปัญหาคอขวดที่ Master Node เมื่อไฟล์เยอะเกินไป (Metadata เยอะ)\n",
    "- Colossus กระจายการจัดการ Metadata ทำให้รองรับไฟล์ระดับ Exabyte ได้จริง และรองรับ Real-time Application\n",
    "\n",
    "\n",
    "\n",
    "**Colossus (Next-Gen GFS)**\n",
    "เมื่อ GFS ถูกใช้งานหนักจนถึงขีดจำกัด Google จึงสร้าง Colossus ที่:\n",
    "- จัดการ Metadata ได้เก่งขึ้น (Scale ได้ระดับ Exabyte)\n",
    "- รองรับ Real-time ได้ดีขึ้น (เพราะบริการเริ่มต้องการความไว)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720380c",
   "metadata": {},
   "source": [
    "### Hadoop Ecosystem (2005–2012)\n",
    "\n",
    "- HDFS: แนวคิด storage แบบกระจาย\n",
    "- MapReduce: batch processing บน cluster\n",
    "\n",
    "บทบาททางประวัติศาสตร์:\n",
    "- ทำให้แนวคิด Big Data เข้าถึงได้ในวงกว้างผ่าน open-source\n",
    "\n",
    "ข้อจำกัด:\n",
    "- Disk-based → latency สูง\n",
    "- พัฒนาและดูแลซับซ้อน\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f42bd2",
   "metadata": {},
   "source": [
    "### NoSQL — เมื่อ RDBMS ไม่ตอบโจทย์ข้อมูลยุคใหม่\n",
    "\n",
    "- Key-value / Document / Columnar\n",
    "- จุดแข็ง: scale ง่าย รองรับข้อมูลหลากหลายรูปแบบ และ schema ยืดหยุ่น\n",
    "- จุดอ่อน: คุณสมบัติด้านความสอดคล้องของข้อมูล (consistency) และการ query บางรูปแบบอาจต่างจาก RDBMS (ขึ้นกับระบบ)\n",
    "\n",
    "**บทเรียนเชิงสถาปัตยกรรม**\n",
    "- บางครั้งระบบต้อง “ยอมแลก” บางคุณสมบัติเพื่อแลกกับการ scale และความยืดหยุ่น\n",
    "\n",
    "\n",
    "\n",
    "**เกร็ดความรู้: CAP Theorem**\n",
    "ในระบบกระจาย เรามักต้องเลือกระหว่าง:\n",
    "- **Consistency (C)**: ข้อมูลตรงกันทุกเครื่องทันที\n",
    "- **Availability (A)**: ระบบตอบสนองเสมอแม้บางส่วนมีปัญหา\n",
    "NoSQL ส่วนใหญ่มักเลือก A (ตอบสนองไว) และยอมลด C (ข้อมูลอาจจะ update ไม่พร้อมกันเสี้ยววินาที - Eventual Consistency)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562289d",
   "metadata": {},
   "source": [
    "### Apache Spark (2012+)\n",
    "\n",
    "- In-memory processing ช่วยลดเวลาประมวลผลอย่างมีนัยสำคัญ (เร็วกว่า Hadoop MapReduce ถึง 100 เท่าในบาง tasks)\n",
    "- API ระดับสูง (DataFrame, SQL) ทำให้พัฒนาได้เร็วและปลอดภัยขึ้น\n",
    "- รองรับงานหลายแบบ: Batch, Streaming, Machine Learning, Graph Processing\n",
    "\n",
    "\n",
    "![spark_in_memory_vs_disk](images/spark_in_memory_vs_disk_1768465074016.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f4be5",
   "metadata": {},
   "source": [
    "### Cloud และแนวคิดแยก Storage กับ Compute\n",
    "\n",
    "- Elasticity: เพิ่ม/ลดทรัพยากรได้ตามต้องการ\n",
    "- Pay-as-you-go: จ่ายตามการใช้งานจริง\n",
    "- แยกที่เก็บข้อมูล (object storage) ออกจากเครื่องประมวลผล (compute)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c809b64",
   "metadata": {},
   "source": [
    "### Data Lake — เก็บข้อมูลดิบเพื่อความยืดหยุ่น\n",
    "\n",
    "- เก็บข้อมูลดิบจำนวนมาก รองรับหลายรูปแบบ\n",
    "- schema-on-read ทำให้ยืดหยุ่นต่อคำถามใหม่ ๆ\n",
    "\n",
    "ข้อควรระวัง:\n",
    "- หากไม่มี governance จะกลายเป็น data swamp\n",
    "\n",
    "\n",
    "![datalake_vs_warehouse](images/datalake_vs_warehouse_1768464684861.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a15d09",
   "metadata": {},
   "source": [
    "### Lakehouse และสรุปวิวัฒนาการ\n",
    "\n",
    "- Lakehouse รวมข้อดีของ Data Lake + Warehouse (เช่นความถูกต้องแบบ ACID บนไฟล์)\n",
    "- แนวโน้มปัจจุบัน: analytics + ML + streaming บนข้อมูลชุดเดียวที่บริหารจัดการได้ดี\n",
    "\n",
    "**ช่วงถาม–คิด (ปิดท้าย)**\n",
    "- หากคุณเป็นองค์กรขนาดกลาง คุณควรเริ่มจากแนวคิดใดยุคใดก่อน และเพราะเหตุใด\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9650ff",
   "metadata": {},
   "source": [
    "## Part 4: ทำไม Python ถึงเป็นภาษาหลักของ Big Data\n",
    "\n",
    "### เหตุผลสำคัญ\n",
    "- **อ่านง่าย (Readability)**: โครงสร้างภาษาที่ใกล้เคียงภาษาอังกฤษ ทำให้เรียนรู้ได้เร็ว\n",
    "- **Abstraction สูง**: ซ่อนความซับซ้อนของ memory management ทำให้โฟกัสที่ logic ได้\n",
    "- **Performance ดี**: เมื่อใช้ร่วมกับไลบรารีอย่าง NumPy หรือ Pandas ที่เขียนด้วย C/C++\n",
    "- **Ecosystem**: มีเครื่องมือครบวงจรสำหรับ Data Science (Pandas, Scikit-learn, TensorFlow)\n",
    "- **Portability**: ใช้งานได้ข้ามแพลตฟอร์ม (Windows, Mac, Linux, Cloud)\n",
    "\n",
    "\n",
    "![python_data_ecosystem](images/python_data_ecosystem_1768465097331.png)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a7aec",
   "metadata": {},
   "source": [
    "## Part 5: Python พื้นฐาน (Hands-on)\n",
    "\n",
    "> **เหตุผลที่ต้องเรียนพื้นฐานให้เป็นระบบก่อน**\n",
    "> งาน Big Data ในทางปฏิบัติไม่ได้เริ่มจากการกดปุ่มในเครื่องมือ แต่เริ่มจากการเขียน “กระบวนการ” ที่ทำซ้ำได้ เช่น การอ่านข้อมูล การทำความสะอาด การแปลงรูปแบบ และการวิเคราะห์\n",
    "\n",
    "### ทำไมต้องมีพัฒนาการของแนวคิด (Concept Evolution) ใน Python\n",
    "แนวคิดในภาษาโปรแกรมพัฒนามาจากความต้องการทำให้โค้ด:\n",
    "1) **อ่านง่าย** (readability)\n",
    "2) **ดูแลง่าย** (maintainability)\n",
    "3) **ขยายได้** (scalability of code)\n",
    "4) **ทำงานร่วมกันได้** (collaboration)\n",
    "\n",
    "กล่าวโดยสรุป: เมื่อระบบโตขึ้น การเขียนโค้ดแบบ “คิดเป็นส่วน” (abstraction) และ “มีโครงสร้าง” จะสำคัญมากกว่าการจำคำสั่ง\n",
    "\n",
    "### เชื่อมกับ Data Science Libraries\n",
    "ในโลกข้อมูล Python ถูกใช้อย่างกว้างขวางเพราะมีไลบรารีที่แปลงงานยากให้เป็นคำสั่งระดับสูง เช่น\n",
    "- **NumPy**: คำนวณเชิงตัวเลขและอาร์เรย์อย่างมีประสิทธิภาพ\n",
    "- **Pandas**: จัดการข้อมูลเชิงตาราง (เหมือน spreadsheet แต่ทรงพลังและทำซ้ำได้)\n",
    "- **Matplotlib**: สร้างกราฟเพื่อสื่อสารผลลัพธ์\n",
    "\n",
    "> หลังจากพื้นฐานส่วนนี้ นักศึกษาจะพร้อมเข้าสู่การจัดการข้อมูลด้วย Pandas และขยายไปสู่เครื่องมือ Big Data ในสัปดาห์ถัดไป\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f7f00",
   "metadata": {},
   "source": [
    "### 5.1 Variable & Operation\n",
    "\n",
    "**แนวคิด**\n",
    "ตัวแปรคือชื่อที่ใช้อ้างอิงข้อมูลในหน่วยความจำ เพื่อใช้งานซ้ำได้อย่างเป็นระบบ ส่วน operation คือการคำนวณ/แปลงข้อมูล ซึ่งเป็นหัวใจของการสร้างตัวแปรใหม่และตัวชี้วัดในงานข้อมูลจริง\n",
    "\n",
    "\n",
    "**เปรียบเทียบให้เห็นภาพ**\n",
    "ตัวแปรเหมือน \"กล่องแปะป้ายชื่อ\"\n",
    "- เราสร้างกล่องชื่อ `score` แล้วใส่ค่า `10` ลงไป\n",
    "- เมื่อเราสั่ง `score = 20` คือการเทค่าเดิมทิ้งแล้วใส่ `20` ลงไปแทน\n",
    "- หรือมองว่าป้ายชื่อ `score` ย้ายไปแปะที่ข้อมูลตัวใหม่ก็ได้ (ใน Python จะเป็นแบบนี้)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 1: การกำหนดตัวแปรและคำนวณพื้นฐาน\n",
    "a = 10\n",
    "b = 3\n",
    "\n",
    "(a + b, a - b, a * b, a / b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 2: Arithmetic operations (ครบชุด)\n",
    "# +  บวก\n",
    "# -  ลบ\n",
    "# *  คูณ\n",
    "# /  หาร (float)\n",
    "# // หารปัดเศษลง\n",
    "# %  หารเอาเศษ\n",
    "# ** ยกกำลัง\n",
    "\n",
    "a = 17\n",
    "b = 5\n",
    "{\n",
    "    \"a + b\": a + b,\n",
    "    \"a - b\": a - b,\n",
    "    \"a * b\": a * b,\n",
    "    \"a / b\": a / b,\n",
    "    \"a // b\": a // b,\n",
    "    \"a % b\": a % b,\n",
    "    \"a ** b\": a ** b,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60523887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 3: Augmented assignment\n",
    "x = 10\n",
    "x += 3   # x = x + 3\n",
    "x -= 1   # x = x - 1\n",
    "x *= 2   # x = x * 2\n",
    "x /= 4   # x = x / 4\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 4: Comparison operations\n",
    "a = 10\n",
    "b = 3\n",
    "{\n",
    "    \"a == b\": a == b,\n",
    "    \"a != b\": a != b,\n",
    "    \"a > b\": a > b,\n",
    "    \"a >= b\": a >= b,\n",
    "    \"a < b\": a < b,\n",
    "    \"a <= b\": a <= b,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 5: Logical operations\n",
    "age = 19\n",
    "is_student = True\n",
    "\n",
    "eligible = (age >= 18) and is_student\n",
    "eligible, (not eligible), (eligible or False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd6bf8",
   "metadata": {},
   "source": [
    "**ช่วงถาม–คิด**\n",
    "- การใช้ `//` และ `%` มีประโยชน์ต่อการจัดกลุ่มข้อมูลหรือการทำ partition อย่างไร\n",
    "- ในงานข้อมูลจริง “การเปรียบเทียบ” ถูกใช้บ่อยในขั้นตอนใดของ pipeline\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4f66e",
   "metadata": {},
   "source": [
    "### 5.2 Data Types\n",
    "\n",
    "**แนวคิด**\n",
    "ชนิดข้อมูลมีผลต่อการคำนวณและความหมายของข้อมูล เช่น การบวกเลขกับการต่อข้อความเป็นคนละความหมายกัน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386998eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f05ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10          # int\n",
    "y = 3.14        # float\n",
    "name = \"Data\"   # string\n",
    "flag = True     # boolean\n",
    "\n",
    "(type(x), type(y), type(name), type(flag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d55c4b",
   "metadata": {},
   "source": [
    "**ช่วงถาม–คิด**\n",
    "- หากอ่านข้อมูลจากไฟล์แล้วตัวเลขถูกตีความเป็น string จะกระทบการวิเคราะห์อย่างไร\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35aef1",
   "metadata": {},
   "source": [
    "### 5.3 Python Reserved Words (Keywords)\n",
    "\n",
    "**แนวคิด**\n",
    "คำสงวน (reserved words หรือ keywords) คือคำที่ Python จองไว้ใช้เป็นไวยากรณ์ของภาษา จึงไม่ควรนำไปตั้งเป็นชื่อตัวแปรหรือชื่อฟังก์ชัน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyword\n",
    "keyword.kwlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662699d",
   "metadata": {},
   "source": [
    "**ตัวอย่างข้อควรระวัง**\n",
    "- ไม่ควรตั้งชื่อตัวแปรเป็น `class`, `def`, `for`, `if`, `import`, `return` เป็นต้น\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1e47c",
   "metadata": {},
   "source": [
    "### 5.4 Data Structures\n",
    "\n",
    "**แนวคิด**\n",
    "โครงสร้างข้อมูลช่วยให้จัดเก็บและจัดการข้อมูลหลายค่าพร้อมกันได้อย่างเป็นระบบ ซึ่งเป็นพื้นฐานของการเตรียมข้อมูลก่อนวิเคราะห์\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeea767",
   "metadata": {},
   "source": [
    "#### List\n",
    "\n",
    "\n",
    "**List vs Tuple (เกร็ดเพิ่มเติม)**\n",
    "- **List `[]`**: เหมือน \"กระดาษทด\" ที่เราเขียนเพิ่ม ลบ แก้ไข ได้ตลอดเวลา (Mutable)\n",
    "- **Tuple `()`**: เหมือน \"แผ่นศิลาจารึก\" ที่เขียนแล้วเปลี่ยนไม่ได้ (Immutable) เหมาะกับข้อมูลที่ต้องคงที่ เช่น พิกัด (lat, long) หรือค่า config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4]\n",
    "numbers.append(5)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e0334",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = {\"name\": \"Alice\", \"score\": 85}\n",
    "student[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e24c6e",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43656a",
   "metadata": {},
   "source": [
    "### 5.5 Condition\n",
    "\n",
    "**แนวคิด**\n",
    "โครงสร้างเงื่อนไขใช้กำหนดเส้นทางการทำงานของโปรแกรมตามสถานการณ์ที่แตกต่างกัน เป็นพื้นฐานของตรรกะในงานข้อมูล (เช่น การคัดกรอง/จัดกลุ่ม)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 72\n",
    "\n",
    "if score >= 80:\n",
    "    result = \"A\"\n",
    "elif score >= 70:\n",
    "    result = \"B\"\n",
    "else:\n",
    "    result = \"C\"\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9b2b9",
   "metadata": {},
   "source": [
    "**ช่วงถาม–คิด**\n",
    "- หากเพิ่มเกณฑ์คะแนนใหม่ ต้องปรับโค้ดส่วนใด\n",
    "- ระบบให้เกรดขนาดใหญ่ควรใช้ if-else อย่างเดียวเพียงพอหรือไม่\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb3b87",
   "metadata": {},
   "source": [
    "### 5.6 Loop\n",
    "\n",
    "**แนวคิด**\n",
    "ลูปช่วยให้ทำงานซ้ำได้อัตโนมัติ เหมาะกับงานที่ต้องทำกับข้อมูลหลายรายการ เช่น การคำนวณค่าจากหลายแถว หรือการประมวลผลรายการข้อมูล\n",
    "\n",
    "![loop_logic_flowchart](images/loop_logic_flowchart_1768465154736.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4679335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "for n in numbers:\n",
    "    print(n * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c99750",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6634e19",
   "metadata": {},
   "source": [
    "### 5.6.1 Function\n",
    "\n",
    "**แนวคิด**\n",
    "ฟังก์ชันช่วยย่อยโค้ดเป็นหน่วยย่อย ทำให้โค้ดอ่านง่าย ทดสอบง่าย และนำกลับมาใช้ซ้ำได้ ซึ่งสำคัญมากเมื่อโครงงานมีหลายขั้นตอน\n",
    "\n",
    "\n",
    "**Best Practice**\n",
    "- 1 ฟังก์ชัน ควรทำแค่ 1 หน้าที่\n",
    "- ชื่อฟังก์ชันควรเป็น \"คำกริยา\" ที่สื่อความหมาย เช่น `calculate_tax()`, `clean_data()`\n",
    "- หากฟังก์ชันยาวเกินไป ควรแตกเป็นฟังก์ชันย่อย\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(x, y):\n",
    "    return (x + y) / 2\n",
    "\n",
    "average(10, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fd183",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad14f6",
   "metadata": {},
   "source": [
    "### 5.7 Class & Object\n",
    "\n",
    "**แนวคิด**\n",
    "เมื่อโปรแกรมมีความซับซ้อนมากขึ้น เราต้องจัดกลุ่ม “ข้อมูล” และ “พฤติกรรม” ให้อยู่ด้วยกันอย่างเป็นระบบ (Object-Oriented Programming)\n",
    "\n",
    "- **Class** คือแม่แบบที่กำหนดว่าออบเจ็กต์ควรมีข้อมูล (attributes) และความสามารถ (methods) อะไร\n",
    "- **Object (Instance)** คือสิ่งที่ถูกสร้างจาก class\n",
    "\n",
    "เหตุผลที่ใช้ class/object:\n",
    "- ทำให้โค้ดอ่านง่ายขึ้นเมื่อระบบใหญ่\n",
    "- ลดความซ้ำซ้อน\n",
    "- แยกความรับผิดชอบของแต่ละส่วน (encapsulation)\n",
    "\n",
    "![class_vs_object_metaphor](images/class_vs_object_metaphor_1768465178507.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 1: Class พื้นฐาน (Student)\n",
    "class Student:\n",
    "    def __init__(self, name, score):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "\n",
    "    def grade(self):\n",
    "        return \"Pass\" if self.score >= 60 else \"Fail\"\n",
    "\n",
    "s1 = Student(\"Bob\", 75)\n",
    "s2 = Student(\"Alice\", 55)\n",
    "\n",
    "(s1.name, s1.score, s1.grade()), (s2.name, s2.score, s2.grade())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง 2: เพิ่มพฤติกรรมและการปรับปรุงข้อมูล (Update)\n",
    "class Student:\n",
    "    def __init__(self, name, score):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "\n",
    "    def add_bonus(self, bonus):\n",
    "        self.score += bonus\n",
    "\n",
    "    def grade(self):\n",
    "        return \"Pass\" if self.score >= 60 else \"Fail\"\n",
    "\n",
    "    def summary(self):\n",
    "        return f\"{self.name}: score={self.score}, status={self.grade()}\"\n",
    "\n",
    "s = Student(\"Chris\", 58)\n",
    "s.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.add_bonus(5)\n",
    "s.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0fc09",
   "metadata": {},
   "source": [
    "**ช่วงถาม–คิด**\n",
    "- หากระบบมีนักศึกษาหลายพันคน class/object ช่วยให้จัดการกฎและการคำนวณได้อย่างไร\n",
    "- แนวคิดนี้เชื่อมกับการออกแบบ pipeline หรือ dataset object ได้อย่างไร\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5f08c",
   "metadata": {},
   "source": [
    "### 5.8 Import Module\n",
    "\n",
    "**แนวคิด**\n",
    "การนำเข้าโมดูลทำให้เราใช้ความสามารถที่มีอยู่แล้วในมาตรฐานของภาษาและไลบรารีภายนอก ลดการเขียนซ้ำและทำให้ทำงานบนมาตรฐานเดียวกัน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2da9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82cec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d6373",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299fe364",
   "metadata": {},
   "source": [
    "## Part 6: Python สำหรับ Data Science\n",
    "\n",
    "### 6.1 NumPy\n",
    "\n",
    "**แนวคิด**\n",
    "NumPy เป็นไลบรารีพื้นฐานด้านการคำนวณเชิงตัวเลข (numerical computing) โดยออกแบบให้ทำงานกับข้อมูลแบบอาร์เรย์ (array) ได้รวดเร็ว และรองรับการคำนวณแบบเวกเตอร์ (vectorization) ซึ่งเป็นพื้นฐานของการประมวลผลข้อมูลจำนวนมาก\n",
    "\n",
    "\n",
    "![numpy_vs_list](images/numpy_vs_list_1768464708033.png)\n",
    "\n",
    "\n",
    "\n",
    "**ฟีเจอร์เด็ด: Broadcasting**\n",
    "NumPy ฉลาดพอที่จะคำนวณอาร์เรย์ที่มีขนาดต่างกันได้โดยไม่ต้องวนลูปเอง\n",
    "เช่น เอา `[1, 2, 3]` คูณกับ `2` มันจะกระจายเลข 2 ไปคูณทุกตัวให้อัตโนมัติ (`[2, 4, 6]`)\n",
    "ทำให้โค้ดสั้นและทำงานไวมาก\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d410cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd259e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4])\n",
    "(arr.mean(), arr.sum(), arr.min(), arr.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization: เพิ่ม 10% ให้ทุกค่าในครั้งเดียว\n",
    "x = np.array([10, 20, 30, 40])\n",
    "x * 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างข้อมูลจำลอง (synthetic data) เพื่อทดลอง\n",
    "np.random.seed(42)\n",
    "values = np.random.normal(loc=70, scale=10, size=20)\n",
    "values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a5654",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa5bf7",
   "metadata": {},
   "source": [
    "### 6.2 Pandas\n",
    "\n",
    "**แนวคิด**\n",
    "Pandas ใช้จัดการข้อมูลเชิงตาราง (เหมือน spreadsheet แต่ทำซ้ำได้) เหมาะกับขั้นตอน ingest/clean/transform ใน pipeline ขนาดย่อม\n",
    "\n",
    "![pandas_dataframe_structure](images/pandas_dataframe_structure_1768464733427.png)\n",
    "\n",
    "\n",
    "\n",
    "**โครงสร้างข้อมูล: Series vs DataFrame**\n",
    "- **Series**: ข้อมูล 1 มิติ (เหมือนคอลัมน์เดียวใน Excel หรือ List ที่มี Index)\n",
    "- **DataFrame**: ข้อมูล 2 มิติ (เหมือนตาราง Excel ทั้งแผ่น) ประกอบด้วยหลาย Series มารวมกัน\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74584f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"city\": [\"Bangkok\", \"Chiang Mai\", \"Phuket\", \"Bangkok\"],\n",
    "    \"population_m\": [10.7, 1.2, 0.4, 10.7],\n",
    "    \"visitors_k\": [120, 35, 50, 130],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างคอลัมน์ใหม่จากการคำนวณ\n",
    "df[\"visitors_per_million\"] = df[\"visitors_k\"] / df[\"population_m\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603959d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สรุปข้อมูลด้วย groupby + agg\n",
    "summary = df.groupby(\"city\").agg(\n",
    "    avg_visitors_k=(\"visitors_k\", \"mean\"),\n",
    "    rows=(\"city\", \"count\"),\n",
    ").reset_index()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39da68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง missing values และการทำความสะอาด\n",
    "df2 = df.copy()\n",
    "df2.loc[1, \"visitors_k\"] = None\n",
    "\n",
    "df2.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"visitors_k\"] = df2[\"visitors_k\"].fillna(df2[\"visitors_k\"].mean())\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd708fd9",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5768c",
   "metadata": {},
   "source": [
    "### 6.3 Matplotlib\n",
    "\n",
    "**แนวคิด**\n",
    "Visualization มีเป้าหมายเพื่อสื่อสารแนวโน้ม ความสัมพันธ์ และความผิดปกติของข้อมูล กราฟที่ดีช่วยให้ตรวจสอบและอธิบาย insight ได้ชัดเจน\n",
    "\n",
    "![matplotlib_chart_types](images/matplotlib_chart_types_1768465212197.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaecc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# พื้นที่สำหรับทดลองเขียนโค้ด\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(df[\"city\"], df[\"visitors_k\"])\n",
    "plt.title(\"Visitors by City\")\n",
    "plt.ylabel(\"Visitors (thousand)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286286b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(summary[\"city\"], summary[\"avg_visitors_k\"], marker=\"o\")\n",
    "plt.title(\"Average Visitors by City\")\n",
    "plt.ylabel(\"Avg visitors (thousand)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(values, bins=8)\n",
    "plt.title(\"Distribution of Simulated Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e92814",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1e926",
   "metadata": {},
   "source": [
    "## Part 7: เชื่อมโยงไป Big Data\n",
    "\n",
    "- Pandas คือจุดเริ่มต้น\n",
    "- เมื่อข้อมูลใหญ่ขึ้น → Spark / Distributed System\n",
    "- โค้ดและแนวคิดยังเหมือนเดิม\n",
    "\n",
    "> **Big Data = Python + แนวคิดระบบ**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8feaf7",
   "metadata": {},
   "source": [
    "## Part 8: สรุปท้ายคาบ\n",
    "\n",
    "### สิ่งที่นักศึกษาควรได้วันนี้\n",
    "- เข้าใจภาพรวม Big Data\n",
    "- เห็นบทบาทของ Python\n",
    "- เขียน Python พื้นฐานได้\n",
    "\n",
    "### เตรียมตัวสัปดาห์หน้า\n",
    "- อ่านเรื่อง CSV vs Parquet\n",
    "- ทดลองใช้ Pandas เพิ่มเติม\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  },
  "title": "Big Data Week 1 – Introduction + Python Fundamentals (4 Hours)"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}